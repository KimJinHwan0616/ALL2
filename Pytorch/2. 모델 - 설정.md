## 설정
```
learning_rate = 학습률
cost_function = 비용_함수

optimizer = 옵티마이저
```

+ ### 비용 함수
  >크로스 엔트로피
  >```
  >nn.CrossEntropyLoss().to(device)
  >```
  >
  >평균 제곱 오차
  >```
  >nn.MSELoss(reduction = 'sum').to(device)
  >```
  
+ ### 옵티마이저
  >SGD
  >```
  >torch.optim.SGD(
  >    params = model.parameters()
  >    , lr = learning_rate    # 학습률
  >    , momentum=0
  >    , dampening=0
  >    , weight_decay=0
  >    , nesterov = False    # True: NAG
  >    , maximize=False
  >    , foreach=None
  >    , differentiable=False
  >    )
  >```
  >Adam
  >```
  >torch.optim.Adam(
  >    params = model.parameters()
  >    , lr = 0.001    # 학습률
  >    , betas=(0.9, 0.999)
  >    , eps=1e-08
  >    , weight_decay=0
  >    , amsgrad=False
  >    , foreach=None
  >    , maximize=False
  >    , capturable=False
  >    , differentiable=False
  >    , fused=False
  >    )
  >```