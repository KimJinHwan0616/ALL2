># 데이터 전처리
>
>### 변환, 데이터셋
---

## 변환
```
transforms = transforms.Compose([
    transforms.Resize( size = [세로, 가로] ),    # 크기 변경
    transforms.ToTensor(),    # 이미지(0~255) → 텐서(0~1)
    transforms.Normalize(    # 정규화( (x - mean) / std )
    # mean = [숫자, ], std = [숫자, ]    # 흑백
    mean = [숫자, 숫자, 숫자], std = [숫자, 숫자, 숫자]    # 컬러
        )        
    ])
```

## 데이터셋
`MNIST`, `CIFAR10`
```
def get_dataloaders_데이터셋(
    batch_size,
    num_workers = 0,
    valid_ratio = None,    # 검증 데이터셋 비율(0~1)
    train_transforms = None,
    test_transforms = None
    ):

    if train_transforms is None:
        train_transforms = transforms

    if test_transforms is None:
        test_transforms = transforms

    train_dataset = datasets.데이터셋(
        root='data',
        train=True,
        transform=train_transforms,
        download=True
        )

    valid_dataset = datasets.데이터셋(
        root='data',
        train=True,
        transform=test_transforms
        )

    test_dataset = datasets.데이터셋(
        root='data',
        train=False,
        transform=test_transforms
        )
        
    print(f'''
    <데이터셋 크기>
    훈련 데이터셋: {len(train_dataset)}
    테스트 데이터셋: {len(test_dataset)}
    전체 데이터셋: {len(train_dataset) + len(test_dataset)}
    ''')
    
    if valid_ratio is not None:
        num = int( valid_ratio * len(train_dataset) )
        train_indices = torch.arange(0, len(train_dataset) - num)    # tensor( [0, 1, ..., 60000 - num - 1] )
        valid_indices = torch.arange( len(train_dataset) - num, len(train_dataset) )    # tensor( [60000 - num, ..., 60000 - 1] )

        # 랜덤 샘플링
        train_sampler = SubsetRandomSampler(train_indices)    # [tensor(값), ..., tensor(값)]
        valid_sampler = SubsetRandomSampler(valid_indices)    # [tensor(값), ..., tensor(값)]

        train_loader = DataLoader(
            dataset=train_dataset,
            batch_size=batch_size,
            num_workers=num_workers,
            drop_last=True,
            sampler=train_sampler
            )

        valid_loader = DataLoader(
            dataset=valid_dataset,
            batch_size=batch_size,
            num_workers=num_workers,
            sampler=valid_sampler
            )

    else:
        train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=batch_size,
        num_workers=num_workers,
        drop_last=True,
        shuffle=True
        )

    test_loader = DataLoader(
        dataset=test_dataset,
        batch_size=batch_size,
        num_workers = num_workers,
        shuffle=False
        )

    if valid_ratio is None:
        print(f'''
        <배치 수>
        훈련 데이터: {len(train_loader)}
        테스트 데이터: {len(test_loader)}
        ''')
    
        return train_loader, test_loader

    else:
        print(f'''
        <배치 수>
        훈련 데이터: {len(train_loader)}
        검증 데이터: {len(valid_loader)}
        테스트 데이터: {len(test_loader)}
        ''')
        
        return train_loader, valid_loader, test_loader
```

+ ### 훈련, 검증, 테스트
    ```
    batch_size = 배치_크기
    
    train_loader, valid_loader, test_loader = get_dataloaders_데이터셋(
        batch_size = batch_size,
        valid_ratio = 비율,    # 0 ~ 1셋
        train_transforms = transforms,
        test_transforms = transforms
        )
    ```

+ ### 훈련, 테스트
    ```
    batch_size = 배치_크기
    
    train_loader, test_loader = get_dataloaders_데이터셋(
        batch_size = batch_size,
        valid_ratio = None,    
        train_transforms = transforms,
        test_transforms = transforms
        )
    ```


