2 ㅇ
첫번째로 인공 신경망의 '정의'와 퍼셉트론과 관련된 용어들을 살펴보고

두번째로 신경망이 어떻게 학습하는지에 대한 '학습 과정'과
학습 과정 중에 발생하는 여러 가지 '문제점'들을 알아보고

세번째로 합성곱 신경망(CNN)이 만들어진 '등장 배경'과 이와 관련된 '용어'들을 살펴본 후에

마지막으로 사전 훈련된 모델을 사용해야 하는 '이유'와
합성곱 신경망(CNN)과 관련된 다양한 사전 훈련된 모델들의 '신경망 구조'를 알아보겠습니다.

3 ㅇ
1장에서의 핵심은 ~ 으며 ~ 입니다

이 핵심 내용들을 머릿속에 기억해두시고 세미나를 들으시면
개념과 원리를 쉽게 이해하는데 도움이 될 것입니다.

4 ㅇ
인간은 어떻게 기계를 학습을 시켜야하나 고민하던 중
사람의 지능을 가진 기계를 만들려면
사람이 배우는 방법이랑 똑같이 만들면 되지 않을까하고 생각해보니
사람은 무언가를 배울 때 어떻게 배우지? 라는 생각을 하게됩니다

그래서 ~ 인 인공 신경망을 만들게 되었습니다.

뉴런을 인공 신경망에서는 노드라고 부르며
입력값을 받아서 가중치를 곱해서 노드에 전달하고
노드에 전달된 값이 특정 임계값보다 크면 출력을 하는 구조로 인공 신경망을 만들었습니다.

5 ㅇ
퍼셉트론이란 ~ 입니다.
입력값에 해당하는 가중치를 곱하고 편향을 더해서 노드에 전달하면
노드에서 가중합을 만들고 활성화 함수를 통과하면 출력값이 나오는 구조입니다.

퍼셉트론은 가중합, 활성화 함수, 층으로 이루어져 있으며
층의 갯수에 따라서 단층과 다층으로 구분할 수 있습니다.

그럼 각각 가중합, 활성화 함수, 층의 의미를 하나하나 살펴보겠습니다.

6 ㅇ
가중합은 ~ 입니다.
가중합을 구하는 공식은 다음과 같습니다.

7 ㅇ
가중치는 중요도라고 이해하면 됩니다.

예를들면, 우리가 학생의 6월, 9월 성적을 가지고 수능점수를 예측하려고 합니다.
일반적인 통계를 바탕으로 우리(인간)가 6월, 9월 성적 중 어떤 성적을 많이 참고해야할지 생각해보라고 할 때
9월 성적을 많이 참고하겠죠? 왜?
9월 성적이 수능 날짜와 가장 가까우므로 이 성적 그대로가 수능 성적일 가능성이 높기 때문입니다.

그런데, 신경망은 6월, 9월 중 어떤 성적을 많이 참고해야할지를 수학적으로 판단해야하기 때문에
6월, 9월 성적의 참고 정도를 다르게 하기위해서
각각의 성적에 가중치라는 값을 곱해줌으로써 성적의 중요도를 표시를 해 주는 것입니다.

8 ㅇ
편향은 신경망의 활성화 정도입니다.

예를들어, 가산점 같이 6월,9월 성적과 관련은 없는데
수능 성적에 관련있는 요소를 말합니다.

9 ㅇ
일단 넘어가기

10 ㅇ
활성화 함수는 ~ 입니다.

11 ~ 13 ㅇ
활성화 함수는 여러가지가 있으며
뒤에서 더 자세하게 다룰 예정이니
이러한 활성화 함수가 있구나 하고 지금은 넘어가시면 됩니다.

9 ㅇ
아래 그림을 보면
편향에 곱해지는 입력값이 항상 1로 고정되어 있는데

그 이유는 위 그림 처럼 편향이 없는 신경망에서
활성화 함수가 출력되는 조건식의 θ를 좌변에 이항한 후에 -θ를 b로 치환했기 때문입니다.

그리고 b를 노드로 표현하면 가중합에서 입력값이 1이고 b를 곱해서 더한 값들 중 하나라고 표현할 수 있습니다.

간단하게 정리하면
편향이 없는 신경망은 임계값이 θ인 경우고
편향이 있는 신경망은 임계값을 0으로 바꾼 후 편향을 추가한 경우입니다.

어떤 값을 비교할 때, 0을 기준으로 비교하는 것이 수학적으로 표현하기 쉽기 때문에
아래 그림처럼 편향이 있는 신경망을 사용합니다.

다시 편향의 의미로 돌아와서
b값이 커지면?  임계값θ은 작아지죠?
임계값이 작아진다는 의미는 활성화 함수를 통해 더 많은 값이 출력 할 수 있다는 의미
즉, 활성화가 증가한다는 의미입니다.

<< 칠판 설명 >>
쉽게 말해서
1 2 3 4 5 값이 있다고 할 때
x가 2보다 크면(x>2) 3,4,5가 출력되지만
x가 1보다 크면(x>1) 2,3,4,5가 출력됩니다.
임계값이 2에서 1로 작아졌더니 더 많은 값을 출력하죠?

b가 커지면 임계값이 작아지면서 더 많은 값을 출력하니까
b가 커지면 더 많은 값을 출력해서 활성화 정도가 커지고
b가 작아지면 더 적은 값을 출력하니 활성화 정도가 낮아지는 구나
아.. 그래서 b가 신경망의 활성화 정도를 의미하는것이구나 하고 이해하시면됩니다.

14 ~ 15 ㅇ
층은 노드 집합이며
층에는 입력층, 출력층, 은닉층, 완전연결층이 있습니다.

(층 개념 설명)

16 ㅇ
지금까지 퍼셉트론을 구성하고 있는 가중합, 활성화 함수, 층을 알아봤으니
이제는 퍼셉트론 종류들을 알아보겠습니다.

퍼셉트론은 층 수에 따라서 단층 퍼셉트론, 다층 퍼셉트론으로 구분할 수 있습니다.
단층 퍼셉트론은 입력층과 출력층으로만 구성되어 있으며
단층 퍼셉트론이 논리 구조인 AND, NAND, OR 게이트를 어떻게 구현하는지 살펴보겠습니다.

17 ㅇ
먼저 AND 게이트는 두 개의 입력값(0 또는 1)을 받아서 입력값이 모두 1일때만 출력값이 1이되는 논리 구조입니다.

AND 게이트를 단층 퍼셉트론으로 구현하기 위해서는
입력층에서 입력값(0 또는 1)을 받아서 각각 가중치를 곱하고 편향을 더해서 가중합을 만들어주고
활성화 함수인 계단 함수를 사용하여
출력층에서 가중합이 0이상 일 때(즉, ｘ₁ｗ₁ + ｘ₂ｗ₂ + b ≥ 0)는 출력값을 1로
0보다 작을 때(ｘ₁ｗ₁ + ｘ₂ｗ₂ + b < 0) 는 출력값을 0으로 나타낼 수 있으므로
AND 게이트를 단층 퍼셉트론으로 표현할 수 있습니다.

좀 더 이해하기 쉽게 단층 퍼셉트론을 시각화하면
입력값 x1, x2의 좌표평면에 출력값 0을 하얀색 원, 출력값 1을 검은색 원으로 표현했습니다.

가중합으로 표현된 직선을 기준으로
윗 영역에서는 활성화 시키고, 아래 영역은 활성화시키지 않으므로
검정색 원과 하얀색 원을 직선으로 구분하는 것을 보여주고 있습니다.

18 ~ 19 ㅇ
마찬가지로 NAND, OR 게이트로 단층 퍼셉트론으로 구현할 수 있습니다.

20 ㅇ
XOR 게이트는 두 개의 입력값(0 또는 1)을 받아서 입력값이 서로 같을때 출력값이 0이 되는 논리 구조입니다.
하지만, XOR 게이트를 단층 퍼셉트론으로 구현하려고 보니
이전 게이트처럼 표현이 안된다는 겁니다.

이쪽으로 직선을 긋자니 ~~~

그래서 어떻게하면 구현할 수 있을까 곰곰히 생각해보다가

21 ㅇ
다층 퍼셉트론의 개념이 나오게 됩니다.
즉, 입력층과 출력층 사이에 층을 하나 더 추가하면 XOR 게이트를 표현할 수 있지 않을까? 해서 층을 늘려보기 시작합니다.

22 ㅇ
XOR 게이트는 NAND 게이트와 OR 게이트를 조합하면 구현할 수 있습니다.
퍼셉트론 관점에서는 층을 더 쌓는 것과 같은 맥락입니다.

마찬가지로 다층 퍼셉트론을 시각화하면
NAND 게이트와 OR게이트의 각각 가중합으로 표현된 직선을 기준으로
검정색 원과 하얀색 원을 두 개의 직선으로 구분할 수 있음을 보여주고 있습니다.

23 ㅇ
이런 식으로 우리는 층과 뉴런을 추가해주고
다양한 활성화 함수들을 사용하면은 복잡한 문제들을 해결할 수 있겠구나 해서
딥러닝이라고 부르는 심층 신경망의 개념이 등장하게 됩니다.





